{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10527b0",
   "metadata": {},
   "source": [
    "# A brief introduction to the patent system\n",
    "The patent is a register, tipically a document, that to document a exclusive discovery, invention or method and aims to give to the patent holder exclusive rights over the discovery/invention.\n",
    "\n",
    "<--TODO: Explain the T,O method of organizing patents -->\n",
    "\n",
    "To organize the patents and find a suitable way to structure its information, a commonly used method defines a patent with 2 characteristics:\n",
    "1. **Task:** the method used in the described patent. In can be compress something or agilize a effect, for example.\n",
    "2. **Object:** the \"target\" of the task. It can be a food, a construction material or any other object that, combined with the task, defines the patent.\n",
    "\n",
    "This method is defined by the Hallbach matrix, that defines a list of Task and Objects that can be extracted from the Title or the Resume of the patent.\n",
    "\n",
    "# T,O Finder\n",
    "The T,O Finder is the method that identifies the Task and the Object from a given patent and in this notebook we will construct a method to do such thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b27e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_pedido</th>\n",
       "      <th>data_deposito</th>\n",
       "      <th>titulo</th>\n",
       "      <th>ipc</th>\n",
       "      <th>url</th>\n",
       "      <th>resumo</th>\n",
       "      <th>classifica_ipc</th>\n",
       "      <th>titulo_lemmatized</th>\n",
       "      <th>resumo_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR 11 2021 018393 0</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>TRATAMENTO DE COLISÕES EM UPLINK</td>\n",
       "      <td>H04L 1/18</td>\n",
       "      <td>https://busca.inpi.gov.br/pePI/servlet/Patente...</td>\n",
       "      <td>A presente invenção se refere a métodos, sis...</td>\n",
       "      <td>H04L 1/18</td>\n",
       "      <td>tratamento colisao uplink</td>\n",
       "      <td>presente invencao referir metodo sistema di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR 11 2021 018071 0</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>ALOJAMENTO DE VELA DE IGNIÇÃO COM PROTEÇÃO ANT...</td>\n",
       "      <td>H01T 13/14</td>\n",
       "      <td>https://busca.inpi.gov.br/pePI/servlet/Patente...</td>\n",
       "      <td>ALOJAMENTO DE VELA DE IGNIÇÃO COM PROTEÇÃO A...</td>\n",
       "      <td>H01T 13/14 ;  H01T 13/20 ;  H01T 13/32 ;  H0...</td>\n",
       "      <td>alojamento vela ignicao protecao anticorrosivo...</td>\n",
       "      <td>alojamento vela ignicao protecao anticorros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR 11 2021 016947 4</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>ANTICORPOS QUE RECONHECEM TAU</td>\n",
       "      <td>C07K 16/18</td>\n",
       "      <td>https://busca.inpi.gov.br/pePI/servlet/Patente...</td>\n",
       "      <td>ANTICORPOS QUE RECONHECEM TAU. A invenção fo...</td>\n",
       "      <td>C07K 16/18 ;  G01N 33/68</td>\n",
       "      <td>anticorpo reconhecer tau</td>\n",
       "      <td>anticorpo reconhecer tau invencao fornecer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR 10 2020 004169 0</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>AQUECEDOR DE AR A LENHA COM DUPLA EXAUSTÃO PAR...</td>\n",
       "      <td>F24H 3/00</td>\n",
       "      <td>https://busca.inpi.gov.br/pePI/servlet/Patente...</td>\n",
       "      <td>AQUECEDOR DE AR A LENHA COM DUPLA EXAUSTAO P...</td>\n",
       "      <td>F24H 3/008 ;  F24H 4/06</td>\n",
       "      <td>aquecedor ar lenha dupla exaustao utilizar amb...</td>\n",
       "      <td>aquecedor ar lenha dupla exaustao utilizar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR 11 2021 006234 3</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>BIBLIOTECAS DE CÉLULAS ÚNICAS E NÚCLEOS ÚNICOS...</td>\n",
       "      <td>C12N 15/10</td>\n",
       "      <td>https://busca.inpi.gov.br/pePI/servlet/Patente...</td>\n",
       "      <td>BIBLIOTECAS DE CÉLULAS ÚNICAS E NÚCLEOS ÚNIC...</td>\n",
       "      <td>C12N 15/10</td>\n",
       "      <td>biblioteca celula unico nucleo unico alto rend...</td>\n",
       "      <td>biblioteca celula unico nucleo unico alto r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id_pedido data_deposito  \\\n",
       "0  BR 11 2021 018393 0    02/03/2020   \n",
       "1  BR 11 2021 018071 0    02/03/2020   \n",
       "2  BR 11 2021 016947 4    02/03/2020   \n",
       "3  BR 10 2020 004169 0    02/03/2020   \n",
       "4  BR 11 2021 006234 3    02/03/2020   \n",
       "\n",
       "                                              titulo         ipc  \\\n",
       "0                   TRATAMENTO DE COLISÕES EM UPLINK   H04L 1/18   \n",
       "1  ALOJAMENTO DE VELA DE IGNIÇÃO COM PROTEÇÃO ANT...  H01T 13/14   \n",
       "2                      ANTICORPOS QUE RECONHECEM TAU  C07K 16/18   \n",
       "3  AQUECEDOR DE AR A LENHA COM DUPLA EXAUSTÃO PAR...   F24H 3/00   \n",
       "4  BIBLIOTECAS DE CÉLULAS ÚNICAS E NÚCLEOS ÚNICOS...  C12N 15/10   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://busca.inpi.gov.br/pePI/servlet/Patente...   \n",
       "1  https://busca.inpi.gov.br/pePI/servlet/Patente...   \n",
       "2  https://busca.inpi.gov.br/pePI/servlet/Patente...   \n",
       "3  https://busca.inpi.gov.br/pePI/servlet/Patente...   \n",
       "4  https://busca.inpi.gov.br/pePI/servlet/Patente...   \n",
       "\n",
       "                                              resumo  \\\n",
       "0    A presente invenção se refere a métodos, sis...   \n",
       "1    ALOJAMENTO DE VELA DE IGNIÇÃO COM PROTEÇÃO A...   \n",
       "2    ANTICORPOS QUE RECONHECEM TAU. A invenção fo...   \n",
       "3    AQUECEDOR DE AR A LENHA COM DUPLA EXAUSTAO P...   \n",
       "4    BIBLIOTECAS DE CÉLULAS ÚNICAS E NÚCLEOS ÚNIC...   \n",
       "\n",
       "                                      classifica_ipc  \\\n",
       "0                                          H04L 1/18   \n",
       "1    H01T 13/14 ;  H01T 13/20 ;  H01T 13/32 ;  H0...   \n",
       "2                           C07K 16/18 ;  G01N 33/68   \n",
       "3                            F24H 3/008 ;  F24H 4/06   \n",
       "4                                         C12N 15/10   \n",
       "\n",
       "                                   titulo_lemmatized  \\\n",
       "0                          tratamento colisao uplink   \n",
       "1  alojamento vela ignicao protecao anticorrosivo...   \n",
       "2                           anticorpo reconhecer tau   \n",
       "3  aquecedor ar lenha dupla exaustao utilizar amb...   \n",
       "4  biblioteca celula unico nucleo unico alto rend...   \n",
       "\n",
       "                                   resumo_lemmatized  \n",
       "0     presente invencao referir metodo sistema di...  \n",
       "1     alojamento vela ignicao protecao anticorros...  \n",
       "2     anticorpo reconhecer tau invencao fornecer ...  \n",
       "3     aquecedor ar lenha dupla exaustao utilizar ...  \n",
       "4     biblioteca celula unico nucleo unico alto r...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the patents dataset\n",
    "df = pd.read_csv('../../data/processed/patentes_inpi_lemmatized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7f3ea",
   "metadata": {},
   "source": [
    "# POS tagging\n",
    "**POS (Part-of-Speech) Tagging** is the process of labeling each word in a text with its corresponding part of speech, such as noun, verb, adjective, etc. This is a fundamental step in Natural Language Processing (NLP) as it helps in understanding the grammatical structure and meaning of a sentence.\n",
    "\n",
    "For example:\n",
    "- Sentence: \"The cat is sleeping.\"\n",
    "- POS Tags: `The (Determiner)`, `cat (Noun)`, `is (Verb)`, `sleeping (Verb)`.\n",
    "\n",
    "POS tagging is useful for tasks like:\n",
    "- Text parsing and syntactic analysis.\n",
    "- Named Entity Recognition (NER).\n",
    "- Sentiment analysis and text classification.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "# Load a spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Replace with your desired language model\n",
    "\n",
    "# Input text\n",
    "text = \"tratamento colisao uplink.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print each token and its POS tag\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "```\n",
    "\n",
    "It gives the following output:\n",
    "\n",
    "```sh\n",
    "tratamento -> NOUN (NOUN)\n",
    "colisao -> ADJ (ADJ)\n",
    "uplink -> VERB (VERB)\n",
    "```\n",
    "\n",
    "## POS Tagging with spaCy\n",
    "spaCy provides an efficient and easy-to-use method for [POS](https://universaldependencies.org/u/pos/) tagging. It extracts from the words the following characteristics:\n",
    "- `token.pos_`: The coarse-grained part-of-speech tag (e.g., NOUN, VERB).\n",
    "- `token.tag_`: The fine-grained part-of-speech tag (e.g., VBZ, NN).\n",
    "\n",
    "In spaCy, each token in a text is assigned with a bunch of characteristics:\n",
    "\n",
    "1. Text: The original word text.\n",
    "2. Lemma: The base form of the word.\n",
    "3. **POS:** The simple UPOS part-of-speech tag.\n",
    "4. **Tag:** The detailed part-of-speech tag.\n",
    "5. Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "6. Shape: The word shape – capitalization, punctuation, digits.\n",
    "7. is alpha: Is the token an alpha character?\n",
    "8. is stop: Is the token part of a stop list, i.e. the most common words of the language?\n",
    "\n",
    "\n",
    "## Reference\n",
    "Common `pos_` Tags\n",
    "| Tag   | Description           |\n",
    "|-------|-----------------------|\n",
    "| `ADJ` | Adjective             |\n",
    "| `ADP` | Adposition            |\n",
    "| `ADV` | Adverb                |\n",
    "| `AUX` | Auxiliary verb        |\n",
    "| `CONJ`| Coordinating conjunction |\n",
    "| `DET` | Determiner            |\n",
    "| `INTJ`| Interjection          |\n",
    "| `NOUN`| Noun                  |\n",
    "| `NUM` | Numeral               |\n",
    "| `PART`| Particle              |\n",
    "| `PRON`| Pronoun               |\n",
    "| `PROPN`| Proper noun          |\n",
    "| `PUNCT`| Punctuation          |\n",
    "| `SCONJ`| Subordinating conjunction |\n",
    "| `SYM` | Symbol                |\n",
    "| `VERB`| Verb                  |\n",
    "| `X`   | Other                 |\n",
    "\n",
    "Common `tag_` Tags (English Example)\n",
    "| Tag   | Description                          |\n",
    "|-------|--------------------------------------|\n",
    "| `NN`  | Noun, singular                      |\n",
    "| `NNS` | Noun, plural                        |\n",
    "| `VB`  | Verb, base form                     |\n",
    "| `VBD` | Verb, past tense                    |\n",
    "| `VBG` | Verb, gerund or present participle  |\n",
    "| `VBN` | Verb, past participle               |\n",
    "| `VBZ` | Verb, 3rd person singular present   |\n",
    "| `JJ`  | Adjective                           |\n",
    "| `RB`  | Adverb                              |\n",
    "| `IN`  | Preposition or subordinating conjunction |\n",
    "| `DT`  | Determiner                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c366d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24077014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text POS\n",
      "metodo -> NOUN (NOUN)\n",
      "codificacao -> ADJ (ADJ)\n",
      "video -> PROPN (PROPN)\n",
      "codificador -> ADJ (ADJ)\n",
      "decodificador -> ADJ (ADJ)\n",
      "produto -> NOUN (NOUN)\n",
      "programa -> ADJ (ADJ)\n",
      "computador -> ADJ (ADJ)\n",
      "\n",
      "\n",
      "Processed text POS\n",
      "MÉTODO -> PROPN (PROPN)\n",
      "DE -> ADP (ADP)\n",
      "CODIFICAÇÃO -> PROPN (PROPN)\n",
      "DE -> PROPN (PROPN)\n",
      "VÍDEO -> PROPN (PROPN)\n",
      ", -> PUNCT (PUNCT)\n",
      "CODIFICADOR -> PROPN (PROPN)\n",
      ", -> PUNCT (PUNCT)\n",
      "DECODIFICADOR -> PROPN (PROPN)\n",
      "E -> CCONJ (CCONJ)\n",
      "PRODUTO -> PROPN (PROPN)\n",
      "DE -> ADP (ADP)\n",
      "PROGRAMA -> PROPN (PROPN)\n",
      "DE -> ADP (ADP)\n",
      "COMPUTADOR -> NOUN (NOUN)\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(df.loc[25, \"titulo_lemmatized\"])\n",
    "\n",
    "# Print each token and its POS tag\n",
    "print(\"Original text POS\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.pos_} ({token.tag_})\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(df.loc[25, \"titulo\"])\n",
    "\n",
    "# Print each token and its POS tag\n",
    "print(\"\\n\\nProcessed text POS\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.pos_} ({token.tag_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9a9e3",
   "metadata": {},
   "source": [
    "As seen, the portuguese POS is not very effection into matching with the words, as it cannot identify properly the Task and Objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b60d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9059c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
